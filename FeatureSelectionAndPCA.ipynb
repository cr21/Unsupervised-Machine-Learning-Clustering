{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureSelectionAndPCA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNaCk2tS3qc0bSrgFrWS0CT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cr21/Unsupervised-Machine-Learning-Clustering/blob/main/FeatureSelectionAndPCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFr8iTU3LakZ",
        "outputId": "8482a59b-db9e-4e7e-80ad-0fc4f6293a1a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ4Nlgqg4fJX",
        "outputId": "ac6a2253-2f4c-4729-ea3e-a8f2609b6c6e"
      },
      "source": [
        "cd drive/MyDrive/Dataset/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytzlH8ofKWr5",
        "outputId": "3bab87d3-7001-482e-ada6-491a096afc72"
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 2gaussian.txt                      model2.log\n",
            " 3gaussian.txt                      model.log\n",
            " blobs.csv                          model.log1\n",
            " blobs.gsheet                       model.log11\n",
            " circle.csv                         model.log.gdoc\n",
            " circle.gsheet                      moons.csv\n",
            "'Convolution Layer.ipynb'           moons.gsheet\n",
            "'Copy of Convolution Layer.ipynb'  'MSR-LA - 3467.docx'\n",
            " dbscan.csv                         \u001b[0m\u001b[01;34mPetImages\u001b[0m/\n",
            " dbscan.gsheet                      processedBlob.csv\n",
            " DensityClusters.ipynb              processedCircle.csv\n",
            " dogscats.npy                       processedMoons.csv\n",
            " dogscats.txt                       proof_1b.jpeg\n",
            " Gaussian_Mixture_Models_2D.ipynb  'readme[1].txt'\n",
            " GaussianMixuerModel.ipynb          spambase.data\n",
            " household_power_consumption.txt    spambase.gdoc\n",
            " kagglecatsanddogs_3367a.zip        spambase.txt\n",
            " \u001b[01;34mMNIST\u001b[0m/                             spamfeatures.txt\n",
            " mnist.log                          training_data.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meA2WDxq5B_F"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import  train_test_split\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdWCKN249G04"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4SoPQ2v9hFR"
      },
      "source": [
        "# Run logistic regression on MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aitGfMMI4jAW"
      },
      "source": [
        "def loadMNIST() :\n",
        "  data= fetch_openml('mnist_784', version=1, return_X_y=False, )  \n",
        "  X = data.data\n",
        "  Y = data.target\n",
        "  target_names = data.target_names\n",
        "  featureNames =  data.feature_names\n",
        "  return X, Y, target_names, featureNames\n",
        "  \n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAZvv-5D5RQU"
      },
      "source": [
        "X, Y, target_names, featureNames= loadMNIST()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ6T3IYJ9lkt",
        "outputId": "47ab0770-6f69-485d-96cb-dea984b6d923"
      },
      "source": [
        "logisticClassfier = LogisticRegression(penalty='l2', tol =0.0001, C = 1.0,n_jobs=-1)\n",
        "logisticClassfier.fit(X_train, y_train)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z4BthfH-AZt",
        "outputId": "5b5cfc00-5b9e-44af-e754-5dc700b6176e"
      },
      "source": [
        "print(f\" train error : {logisticClassfier.score(X_train, y_train)}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " train error : 0.9372494669509595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BmYhxoV-XXd",
        "outputId": "f7aecd34-fa33-496a-ec35-595f11ecf61f"
      },
      "source": [
        "print(f\"test Error : {logisticClassfier.score(X_test, y_test)}\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Error : 0.9190909090909091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-arf0bmB-cdB",
        "outputId": "32c4dc24-ac40-459c-836d-50a49903e73a"
      },
      "source": [
        "# Top 30 features\n",
        "sorted_featuresList = np.argsort(logisticClassfier.coef_)\n",
        "# reverse for maximum to minimum important features\n",
        "reverse_sorted_featuresList = sorted_featuresList[::-1]\n",
        "# select top 30 features\n",
        "top30ids = reverse_sorted_featuresList[:,:30]\n",
        "for id, features in enumerate(top30ids) :\n",
        "  \n",
        "  featureNameList = np.array(featureNames)[features]\n",
        "  print(f\" class : {id} , feature name : {featureNameList}\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " class : 0 , feature name : ['pixel129' 'pixel130' 'pixel573' 'pixel654' 'pixel131' 'pixel687'\n",
            " 'pixel501' 'pixel572' 'pixel416' 'pixel473' 'pixel417' 'pixel500'\n",
            " 'pixel389' 'pixel127' 'pixel445' 'pixel528' 'pixel603' 'pixel150'\n",
            " 'pixel481' 'pixel128' 'pixel132' 'pixel582' 'pixel606' 'pixel529'\n",
            " 'pixel237' 'pixel257' 'pixel571' 'pixel509' 'pixel602' 'pixel361']\n",
            " class : 1 , feature name : ['pixel678' 'pixel415' 'pixel679' 'pixel482' 'pixel650' 'pixel743'\n",
            " 'pixel540' 'pixel744' 'pixel402' 'pixel327' 'pixel416' 'pixel400'\n",
            " 'pixel565' 'pixel468' 'pixel187' 'pixel469' 'pixel502' 'pixel271'\n",
            " 'pixel709' 'pixel297' 'pixel570' 'pixel413' 'pixel414' 'pixel369'\n",
            " 'pixel537' 'pixel742' 'pixel495' 'pixel575' 'pixel626' 'pixel564']\n",
            " class : 2 , feature name : ['pixel377' 'pixel405' 'pixel350' 'pixel595' 'pixel378' 'pixel579'\n",
            " 'pixel349' 'pixel433' 'pixel460' 'pixel555' 'pixel578' 'pixel567'\n",
            " 'pixel583' 'pixel581' 'pixel582' 'pixel596' 'pixel543' 'pixel580'\n",
            " 'pixel665' 'pixel608' 'pixel666' 'pixel664' 'pixel657' 'pixel594'\n",
            " 'pixel611' 'pixel610' 'pixel127' 'pixel568' 'pixel598' 'pixel609']\n",
            " class : 3 , feature name : ['pixel243' 'pixel270' 'pixel244' 'pixel247' 'pixel296' 'pixel481'\n",
            " 'pixel271' 'pixel276' 'pixel277' 'pixel182' 'pixel215' 'pixel293'\n",
            " 'pixel623' 'pixel684' 'pixel306' 'pixel268' 'pixel326' 'pixel248'\n",
            " 'pixel154' 'pixel218' 'pixel356' 'pixel453' 'pixel686' 'pixel334'\n",
            " 'pixel240' 'pixel179' 'pixel153' 'pixel687' 'pixel466' 'pixel272']\n",
            " class : 4 , feature name : ['pixel360' 'pixel329' 'pixel359' 'pixel361' 'pixel388' 'pixel389'\n",
            " 'pixel331' 'pixel358' 'pixel229' 'pixel489' 'pixel330' 'pixel201'\n",
            " 'pixel257' 'pixel269' 'pixel490' 'pixel353' 'pixel147' 'pixel298'\n",
            " 'pixel485' 'pixel458' 'pixel381' 'pixel484' 'pixel457' 'pixel328'\n",
            " 'pixel156' 'pixel652' 'pixel514' 'pixel428' 'pixel663' 'pixel268']\n",
            " class : 5 , feature name : ['pixel98' 'pixel97' 'pixel295' 'pixel323' 'pixel322' 'pixel743'\n",
            " 'pixel545' 'pixel742' 'pixel745' 'pixel741' 'pixel744' 'pixel453'\n",
            " 'pixel747' 'pixel555' 'pixel100' 'pixel304' 'pixel210' 'pixel571'\n",
            " 'pixel351' 'pixel746' 'pixel101' 'pixel125' 'pixel389' 'pixel527'\n",
            " 'pixel445' 'pixel713' 'pixel305' 'pixel187' 'pixel96' 'pixel184']\n",
            " class : 6 , feature name : ['pixel387' 'pixel358' 'pixel517' 'pixel386' 'pixel573' 'pixel487'\n",
            " 'pixel248' 'pixel398' 'pixel515' 'pixel249' 'pixel430' 'pixel316'\n",
            " 'pixel264' 'pixel491' 'pixel457' 'pixel290' 'pixel359' 'pixel277'\n",
            " 'pixel291' 'pixel415' 'pixel661' 'pixel318' 'pixel598' 'pixel486'\n",
            " 'pixel488' 'pixel400' 'pixel305' 'pixel388' 'pixel218' 'pixel188']\n",
            " class : 7 , feature name : ['pixel370' 'pixel371' 'pixel344' 'pixel322' 'pixel342' 'pixel343'\n",
            " 'pixel317' 'pixel319' 'pixel321' 'pixel249' 'pixel443' 'pixel352'\n",
            " 'pixel326' 'pixel597' 'pixel277' 'pixel220' 'pixel372' 'pixel320'\n",
            " 'pixel347' 'pixel135' 'pixel369' 'pixel711' 'pixel324' 'pixel710'\n",
            " 'pixel355' 'pixel221' 'pixel398' 'pixel348' 'pixel305' 'pixel345']\n",
            " class : 8 , feature name : ['pixel466' 'pixel511' 'pixel494' 'pixel375' 'pixel411' 'pixel186'\n",
            " 'pixel711' 'pixel439' 'pixel376' 'pixel467' 'pixel538' 'pixel440'\n",
            " 'pixel483' 'pixel403' 'pixel152' 'pixel630' 'pixel510' 'pixel521'\n",
            " 'pixel717' 'pixel241' 'pixel629' 'pixel689' 'pixel438' 'pixel383'\n",
            " 'pixel384' 'pixel456' 'pixel455' 'pixel178' 'pixel234' 'pixel539']\n",
            " class : 9 , feature name : ['pixel380' 'pixel409' 'pixel379' 'pixel462' 'pixel408' 'pixel324'\n",
            " 'pixel490' 'pixel518' 'pixel352' 'pixel435' 'pixel436' 'pixel463'\n",
            " 'pixel193' 'pixel325' 'pixel715' 'pixel716' 'pixel381' 'pixel407'\n",
            " 'pixel665' 'pixel250' 'pixel222' 'pixel165' 'pixel437' 'pixel491'\n",
            " 'pixel547' 'pixel606' 'pixel178' 'pixel693' 'pixel306' 'pixel323']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xfmvA_YFF3W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdnz4_6_FGVm"
      },
      "source": [
        "#Logistic Regression News Group Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBhFkC6hFJyz"
      },
      "source": [
        "def loadNGData( seed = 20) :\n",
        "  # data = fetch_20newsgroups( remove=('headers','footers','quotes'), random_state= 20)\n",
        "  \n",
        "  dataset = fetch_20newsgroups(subset='all', remove=('headers','footers','quotes'), random_state= seed)\n",
        "  data = dataset.data\n",
        "  labels = dataset.target\n",
        "  features = data\n",
        "  # vectorize the text data\n",
        "  vectorizer = TfidfVectorizer(stop_words='english',min_df = 5)\n",
        "  # vectorize train data\n",
        "  ngVectorData = vectorizer.fit_transform(data)\n",
        "  ngVectorDataDense = ngVectorData.toarray()\n",
        "\n",
        "  return ngVectorDataDense, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0YK7qoJFITA"
      },
      "source": [
        "def load20NG():\n",
        "  dataset = fetch_20newsgroups(subset='all', remove=('headers','footers','quotes'), random_state= 12)\n",
        "  data = dataset.data\n",
        "  labels = dataset.target\n",
        "\n",
        "  vectorizer = TfidfVectorizer(stop_words='english',min_df = 5)\n",
        "\n",
        "  # # vectorize train data\n",
        "  ngVectorData = vectorizer.fit_transform(data)\n",
        "  featureNames = vectorizer.get_feature_names()\n",
        "  return data, labels, ngVectorData, featureNames"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdQxHz0xGzcJ"
      },
      "source": [
        "data, labels, ng20Data, ng20featureNames = load20NG()"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1Cp6BEwGRpA"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(ngVectorData, labels, test_size=0.33, random_state=42)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl4fK0S9HAhY",
        "outputId": "e1806ac7-ddb5-43a0-c1fe-4508d8086191"
      },
      "source": [
        "ngClassfier = LogisticRegression(penalty='l2', tol =0.0001, C = 1.0,n_jobs=-1)\n",
        "ngClassfier.fit(X_train, y_train)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWxmxsl9FtqM",
        "outputId": "efcdbf57-2ddb-468d-eb51-2ff99f1efc76"
      },
      "source": [
        "# training error\n",
        "print(f\" training Error : {ngClassfier.score(X_train, y_train)}\")"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " training Error : 0.8969586567400601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rDgtrqRHYKj",
        "outputId": "a618e93e-3bdf-42bd-f380-1aa2c4c6cbfe"
      },
      "source": [
        "#testing error\n",
        "print(f\" testing Error : {ngClassfier.score(X_test, y_test)}\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " testing Error : 0.732475884244373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKjg1G6SHdGB",
        "outputId": "9ee834c8-23ce-4dfe-bd5a-366b9f3b463c"
      },
      "source": [
        "# Top 30 features\n",
        "sorted_ngFeatureList = np.argsort(ngClassfier.coef_)\n",
        "# reverse for maximum to minimum important features\n",
        "reverse_sorted_ngFeatureList = sorted_ngFeatureList[::-1]\n",
        "# select top 30 features\n",
        "top30NGids = reverse_sorted_ngFeatureList[:,:30]\n",
        "for id, features in enumerate(top30NGids) :\n",
        "  \n",
        "  featureNameList = np.array(ng20featureNames)[features]\n",
        "  print(f\" class : {id} , feature name : {featureNameList}\")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " class : 0 , feature name : ['thanks' 'need' 'year' 'edu' 'problem' 'like' 'work' 'email' 'sure' 'hi'\n",
            " 'drive' 'help' 'best' 'data' 'use' 'computer' 'space' 'sound' 'using'\n",
            " 'software' 'file' 'control' 'phone' 'windows' 'card' 'program' 'games'\n",
            " 'pc' 'news' 'local']\n",
            " class : 1 , feature name : ['thanks' 'god' 'software' 'stuff' 'computer' 'space' 'email' 'religion'\n",
            " 'phone' 'christian' 'available' 'read' 'edu' 'chip' 'jesus' 'info'\n",
            " 'interested' 'file' 'john' 'card' 'team' 'jim' 'work' 'box' 'reply'\n",
            " 'hard' 'advance' 'windows' 'help' 'appreciated']\n",
            " class : 2 , feature name : ['good' 'use' 'thanks' 'com' 'mail' 'god' 'looking' 'new' 'computer'\n",
            " 'list' 'jesus' 'stuff' 'game' 'll' 'data' 'available' 'drive' 'email'\n",
            " 'windows' 'got' 'koresh' 'probably' 'work' 'little' 'haven' 'high' 've'\n",
            " 'version' 'code' 'gun']\n",
            " class : 3 , feature name : ['thanks' 'problem' 'new' 'program' 'software' 'windows' 'book' 'mail'\n",
            " 'bit' 'phone' 'drive' 'looking' 'advance' 'company' 'space' 'games'\n",
            " 'problems' 'cheers' 'israel' 'left' 'systems' 'short' 'key' 'john'\n",
            " 'files' 'using' 'power' 'work' 'sun' 'regards']\n",
            " class : 4 , feature name : ['use' 'government' 'right' 'run' 'windows' 'bad' 'better' 'game' 'drive'\n",
            " 'ra' 'got' 'mr' 'list' 'car' 'computer' 'code' 'program' 'set' 'number'\n",
            " 'data' 'using' '50' 'edu' 'pc' 'kill' 'big' 'kent' 'high' 'price' 'phone']\n",
            " class : 5 , feature name : ['file' 'drive' 'god' 'let' 'windows' 'car' 'does' 'say' 'way' 'computer'\n",
            " 've' 'advance' 'wrong' 'video' 'really' 'help' 'version' 'david' 'game'\n",
            " 'card' 'says' 'graphics' 'hi' 'price' 'window' 'chip' 'word' 'mail'\n",
            " 'religion' 'games']\n",
            " class : 6 , feature name : ['government' 'car' 'windows' 'drive' 'space' 'game' 'software' 'program'\n",
            " 'version' 'price' 'file' 'card' 'god' 'power' 'code' 'pc' 'law'\n",
            " 'religion' 'copy' 'gun' 'didn' 'chip' 'files' 'church' 'guess' 'running'\n",
            " 'christian' 'fbi' 'disk' 'monitor']\n",
            " class : 7 , feature name : ['people' 'government' 'did' 'year' 'windows' 'god' 'person' 'come' 'just'\n",
            " 'sale' 'asking' 'files' 'evidence' 'mac' 'new' 'mouse' 'driver' 'apple'\n",
            " 'dos' 'read' 'love' 'months' 'ms' 'gun' 'unix' 'children' 'team' 'points'\n",
            " 'world' 'public']\n",
            " class : 8 , feature name : ['god' 'year' 'help' 'drive' 'did' 'info' 'thanks' 'car' 'windows' 'game'\n",
            " 'gun' 'sorry' 'ca' 'graphics' 'wondering' 'card' 'claim' 'problems'\n",
            " 'support' 'guy' 'science' 'experience' 'image' 'newsgroup' 'window'\n",
            " 'religion' 'koresh' 'color' 'old' 'city']\n",
            " class : 9 , feature name : ['use' 'com' 'does' 'used' 'work' 'god' 'want' 'program' 'drive'\n",
            " 'question' 'problem' 'info' 'old' 'run' 'government' 'looking' 'windows'\n",
            " 'book' 'read' 'data' 'set' 'software' 'people' 'file' 'case' 'copy' 'hi'\n",
            " 'version' 'car' 'pc']\n",
            " class : 10 , feature name : ['use' 'people' 'email' 'using' 'car' 'windows' 'space' 'need' 'file'\n",
            " 'computer' 'software' 'government' 'used' 'pc' 'state' 'program' 'god'\n",
            " 'version' 've' 'right' 'support' 'quite' 'playoff' 'try' 'told' 'bit'\n",
            " 'nhl' 'friend' 'group' 'code']\n",
            " class : 11 , feature name : ['does' 'people' 'believe' 'information' 'program' 'software' 'problem'\n",
            " 'using' 'computer' 'god' 'version' 'data' 'use' 'government' 'windows'\n",
            " 'games' 'point' 'mail' 'source' 'evidence' 'fact' 'space' 'file'\n",
            " 'question' 'world' 'american' 'thanks' 'university' 'hear' 'monitor']\n",
            " class : 12 , feature name : ['god' 'program' 'bike' 'software' 'game' 'government' 'pc' 'support'\n",
            " 'space' 'card' 'help' 'data' 'use' 'games' 'monitor' 'chip' 'news'\n",
            " 'video' 'able' 'computer' 'line' 'source' 'dos' 'mac' 'evidence' 'files'\n",
            " 'using' 'order' 'team' 'disk']\n",
            " class : 13 , feature name : ['does' 'think' 'know' 'problem' 'don' 'read' 'sure' 'help' 'people'\n",
            " 'right' 'say' 'question' 'heard' 've' 'going' 'better' 'did' 'believe'\n",
            " 'point' 'different' 'thought' 'advance' 'try' 'really' 'info' 'using'\n",
            " 'just' 'doing' 'number' 'actually']\n",
            " class : 14 , feature name : ['think' 'people' 'did' 'said' 'power' 'god' 'mean' 'point' 'card' 'drive'\n",
            " 'high' 'year' 'article' 'day' 'years' 'world' 'buy' 'game' 'modem' 'lot'\n",
            " 'wouldn' 'car' 'driver' 'disk' 'new' 'good' 'ago' 'law' 'say' 'monitor']\n",
            " class : 15 , feature name : ['windows' 'dos' 'people' 'god' 'car' 'com' 'book' 'world' 'controller'\n",
            " 'ide' 'll' 'said' 'news' 'years' 'bios' 'graphics' 'say' 'great' 'change'\n",
            " 'let' 'man' 'maybe' 'example' 'isn' 'quite' 'file' 'didn' 'set' 'aren'\n",
            " 'government']\n",
            " class : 16 , feature name : ['people' 'mac' 'say' 'years' 'think' 'god' 'want' 'life' 'government'\n",
            " 'car' 'word' 'long' 'win' 'open' 'pay' 'books' 'things' 'apple' 'space'\n",
            " 'thought' 'ago' 'home' 'year' 'point' 'list' 'doesn' 'mike' 'public'\n",
            " 'macs' 'current']\n",
            " class : 17 , feature name : ['years' 'said' 'year' 'power' 'time' 'send' 'state' 'bit' 'sale' 'course'\n",
            " 'car' 'god' 'day' 'wouldn' 'did' 'government' 'area' 'hear' 'david'\n",
            " 'week' 'game' 'monitor' 'believe' 'person' 'little' 'people' 'man'\n",
            " 'thing' 'making' 'won']\n",
            " class : 18 , feature name : ['people' 'right' 'drive' 'god' 'believe' 'old' 'government' 'don' 'car'\n",
            " 'used' 'remember' 'idea' 'make' 'power' 'heard' 'say' 'disk' 'just'\n",
            " 'deleted' 'things' 'local' 'cica' 'did' 'fact' 'window' 'thought' 'win'\n",
            " 'came' 'large' 'scsi']\n",
            " class : 19 , feature name : ['thanks' 'mail' 'looking' '10' 'year' 'windows' 'email' 'number' 'work'\n",
            " 'software' 'drive' 'anybody' 'use' 'problem' 'game' 'kind' 'available'\n",
            " 'help' 'new' 'wondering' 'advance' 'data' 'gun' 'message' 'key'\n",
            " 'interested' 'steve' 'children' 'body' 'line']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK3I8aC4IPFC"
      },
      "source": [
        "#Logistic Regression on Spam Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYRRbkr5IT3r"
      },
      "source": [
        "def loadSpamData(fileName = 'spambase.data') :\n",
        "  data = []\n",
        "  labels = []\n",
        "  with open(fileName,'r') as f:\n",
        "    dataset = f.readlines()\n",
        "    for line in dataset:\n",
        "      arr = line.split(\",\")\n",
        "      data.append(arr[:-1])\n",
        "      labels.append(arr[-1])\n",
        "  data = np.array(data).astype(np.float)\n",
        "  labels = np.array(labels).astype(np.float)\n",
        "  \n",
        "  return data, labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFS6wvxwJ6KM"
      },
      "source": [
        "def getFeatureNames(fileName = 'spamfeatures.txt'):\n",
        "  featuresNames =[]\n",
        "  with open(fileName, 'r') as f:\n",
        "    dataset = f.readlines()\n",
        "    for line in dataset:\n",
        "      features = line.split(\":\")[0]\n",
        "      featuresNames.append(features)\n",
        "  return featuresNames"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSN4LmlhK_Vr"
      },
      "source": [
        "data, labels = loadSpamData('spambase.data')\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size = 0.3, random_state = 41)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTqvrvmHL2Re"
      },
      "source": [
        "spamfeatureNames  = getFeatureNames()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSay4obYLDjy",
        "outputId": "33769f33-b405-4948-bf73-9b84bf31401a"
      },
      "source": [
        "spamClassfier = LogisticRegression(penalty='l2', tol =0.0001, C = 1.0,n_jobs=-1)\n",
        "spamClassfier.fit(X_train, Y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEtYhcXYLeoN",
        "outputId": "5bbc1b70-20f5-4734-8a31-7680dd159739"
      },
      "source": [
        "# train error\n",
        "print(f\"train error : {spamClassfier.score(X_train, Y_train)}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train error : 0.9161490683229814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go5aibTiLmQc",
        "outputId": "2e9e171c-2cb0-4597-a9f1-3b804e856c68"
      },
      "source": [
        "# test error\n",
        "print(f\"test error : {spamClassfier.score(X_test, Y_test)}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test error : 0.939174511223751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVRC--8OLlGm",
        "outputId": "4813a4bb-75f5-43cb-e9a9-f8556de9d10a"
      },
      "source": [
        "# Top 30 features\n",
        "sorted_spamFeatureList = np.argsort(spamClassfier.coef_)\n",
        "# reverse for maximum to minimum important features\n",
        "reverse_sorted_spamFeatureList = sorted_spamFeatureList[::-1]\n",
        "# select top 30 features\n",
        "top30spamids = reverse_sorted_spamFeatureList[:,:30]\n",
        "for id, features in enumerate(top30spamids) :\n",
        "  \n",
        "  featureNameList = np.array(spamfeatureNames)[features]\n",
        "  print(f\" class : {id} , feature name : {featureNameList}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " class : 0 , feature name : ['word_freq_george' 'word_freq_hp' 'word_freq_edu' 'word_freq_hpl'\n",
            " 'word_freq_meeting' 'word_freq_re' 'word_freq_project' 'word_freq_data'\n",
            " 'word_freq_lab' 'word_freq_85' 'word_freq_pm' 'char_freq_;'\n",
            " 'word_freq_labs' 'word_freq_cs' 'word_freq_1999' 'word_freq_conference'\n",
            " 'word_freq_telnet' 'word_freq_original' 'word_freq_parts' 'word_freq_415'\n",
            " 'word_freq_857' 'char_freq_[' 'word_freq_will' 'word_freq_table'\n",
            " 'word_freq_direct' 'word_freq_make' 'char_freq_(' 'word_freq_you'\n",
            " 'word_freq_mail' 'word_freq_address']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1740s1XMELb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}